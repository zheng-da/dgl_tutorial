{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "import numpy as np\n",
    "\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "from dgl.data import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a small dataset\n",
    "\n",
    "cora is a small graph of 2708 nodes and 10556 edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Data statistics------'\n",
      "      #Nodes 2708\n",
      "      #Edges 10556\n",
      "      #Classes 7\n",
      "      #Train samples 140\n",
      "      #Val samples 300\n",
      "      #Test samples 1000\n"
     ]
    }
   ],
   "source": [
    "DataArgs = namedtuple('DataArgs', 'dataset')\n",
    "args = DataArgs('cora')\n",
    "data = load_data(args)\n",
    "\n",
    "print(\"\"\"----Data statistics------'\n",
    "      #Nodes %d\n",
    "      #Edges %d\n",
    "      #Classes %d\n",
    "      #Train samples %d\n",
    "      #Val samples %d\n",
    "      #Test samples %d\"\"\" %\n",
    "          (data.graph.number_of_nodes(),\n",
    "           data.graph.number_of_edges(),\n",
    "           data.num_labels,\n",
    "           data.train_mask.sum(),\n",
    "           data.val_mask.sum(),\n",
    "           data.test_mask.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data into DGL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7399375  1.6960521  3.4994125  ... 0.36562112 3.2536626  0.61456096]\n"
     ]
    }
   ],
   "source": [
    "g = dgl.DGLGraph(data.graph, readonly=True)\n",
    "g.ndata['features'] = mx.nd.array(data.features)\n",
    "g.ndata['labels'] = mx.nd.array(data.labels)\n",
    "\n",
    "train_mask = mx.nd.array(data.train_mask)\n",
    "val_mask = mx.nd.array(data.val_mask)\n",
    "test_mask = mx.nd.array(data.test_mask)\n",
    "\n",
    "train_nid = mx.nd.array(np.nonzero(data.train_mask)[0]).astype(np.int64)\n",
    "test_nid = mx.nd.array(np.nonzero(data.test_mask)[0]).astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute a node embedding with  2-layer GCN on a subset of nodes\n",
    "\n",
    "To enable mini-batch training, we need to compute the node embeddings on a subset of nodes. For a 2-layer GCN, we first compute the node embeddings of the neighbors in the first layer of the GCN model.\n",
    "\n",
    "$$h_i^{(1)} = \\sigma(\\Sigma_{j \\in N(i)} h_j^{(0)}), \\forall i \\in N(v)$$\n",
    "\n",
    "Then we compute the node embeddings of the second layer, which is the final embeddings of the nodes in this model.\n",
    "\n",
    "$$h_v^{(2)} = \\sigma(\\Sigma_{i \\in N(v)} h_i^{(1)})$$\n",
    "\n",
    "The data and computation dependency is illustrated in the figure below:\n",
    "![title](https://s3.us-east-2.amazonaws.com/dgl.ai/amlc_tutorial/Dependency.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeUpdate(gluon.Block):\n",
    "    def __init__(self, in_feats, out_feats, activation=None):\n",
    "        super(NodeUpdate, self).__init__()\n",
    "        self.dense = gluon.nn.Dense(out_feats, in_units=in_feats)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, node):\n",
    "        h = node.data['h']\n",
    "        h = self.dense(h)\n",
    "        if self.activation:\n",
    "            h = self.activation(h)\n",
    "        return {'h': h}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input dimension size\n",
    "in_feats = data.features.shape[1]\n",
    "# Hidden dimension size\n",
    "n_hidden = 64\n",
    "\n",
    "# If we want to compute the embeddings of the nodes 0, 1, 2\n",
    "v = [0, 1, 2]\n",
    "\n",
    "nfunc_layer1 = NodeUpdate(in_feats, n_hidden, mx.nd.relu)\n",
    "nfunc_layer2 = NodeUpdate(n_hidden, n_hidden, mx.nd.relu)\n",
    "nfunc_layer1.initialize()\n",
    "nfunc_layer2.initialize()\n",
    "\n",
    "# We first find the neighbors of these nodes.\n",
    "neighbors = np.unique(g.in_edges(v)[0].asnumpy())\n",
    "# compute the embeddings of the neighbors\n",
    "g.pull(neighbors, fn.copy_src('features', 'msg'), fn.sum('msg', 'h'), nfunc_layer1)\n",
    "# compute the embeddings of the nodes in the batch.\n",
    "g.pull(v, fn.copy_src('h', 'msg'), fn.sum('msg', 'h'), nfunc_layer2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computation above is very expensive because computing the node embeddings of the model involve in many neighbor nodes. One solution is to use neighbor sampling to prune some of the dependency.\n",
    "\n",
    "![title](https://s3.us-east-2.amazonaws.com/dgl.ai/amlc_tutorial/neighbor_sampling.png)\n",
    "\n",
    "Neighbor sampling requires to perform pruning in every neighborhood separately. We could implement neighbor sampling with Python as follow. However, the code below is tedious and also very slow when running on a large graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to compute the embeddings of the nodes 0, 1, 2\n",
    "nodes = [0, 1, 2]\n",
    "num_neighs = 4\n",
    "\n",
    "# Sample neighbors in each neighborhood separately.\n",
    "for n in nodes:\n",
    "    src2, dst2 = g.in_edges(n)\n",
    "    idx = np.random.choice(np.arange(len(src2)), size=num_neighs)\n",
    "    src2 = src2[idx]\n",
    "    dst2 = dst2[idx]\n",
    "    \n",
    "    for neighbor in src2:\n",
    "        src1, dst1 = g.in_edges(neighbor)\n",
    "        idx = np.random.choice(np.arange(len(src1)), size=num_neighs)\n",
    "        src1 = src1[idx]\n",
    "        dst1 = dst1[idx]\n",
    "        g.send_and_recv((src1, dst1), fn.copy_src('features', 'msg'), fn.sum('msg', 'h'), nfunc_layer1)\n",
    "        \n",
    "    g.send_and_recv((src2, dst2), fn.copy_src('h', 'msg'), fn.sum('msg', 'h'), nfunc_layer2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a mini-batch (NodeFlow) with neighbor sampling\n",
    "\n",
    "Instead, DGL provides a set of sampling API for various sampling strategies. These sampling APIs create NodeFlows for mini-batch training on a graph.\n",
    "\n",
    "The code below creates a neighbor sampler that creates a NodeFlow with 3 nodes in a batch and samples at maximal 4 neighbors on each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[0 1 2]\n",
       "<NDArray 3 @cpu(0)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler = iter(dgl.contrib.sampling.NeighborSampler(g, 3, num_neighs, neighbor_type='in', num_hops=2))\n",
    "nf = next(sampler)\n",
    "nf.layer_parent_nid(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Have a look at the data inside the NodeFlow.\n",
    "\n",
    "The NodeFlow should have 3 layers and 2 blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nf.num_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nf.num_blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nodes in NodeFlow can be identified by two sets of Ids: global node Id (the node Ids in the original graph) and local node Id (used inside this NodeFlow). Local node Ids inside a NodeFlow are labelled starting from 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[   0  305  333  348  384  565  613  751 1244 1440]\n"
     ]
    }
   ],
   "source": [
    "print(nf.layer_nid(0).asnumpy())\n",
    "print(nf.layer_parent_nid(0).asnumpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NodeFlow should contain 10 nodes to compute node embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sampled nodes in the batch:  [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "nodes = nf.layer_parent_nid(-1).asnumpy()\n",
    "print(\"The sampled nodes in the batch: \", nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nodes in the second layer:  [ 14 344 410 435 565]\n",
      "The in-neighbors of the nodes:  [  8  14 258 344 410 435 471 544 552 565]\n"
     ]
    }
   ],
   "source": [
    "layer1_nodes = nf.layer_parent_nid(1).asnumpy()\n",
    "full_graph_neighbors = g.in_edges(nodes)[0].asnumpy()\n",
    "print(\"The nodes in the second layer: \", layer1_nodes)\n",
    "print(\"The in-neighbors of the nodes: \", np.sort(full_graph_neighbors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data from the parent graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features don't exist in node data of the NodeFlow\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(nf.layers[0].data['features'])\n",
    "except KeyError:\n",
    "    print(\"features don't exist in node data of the NodeFlow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 5. 4.]\n",
      "[2. 5. 4.]\n"
     ]
    }
   ],
   "source": [
    "nf.copy_from_parent()\n",
    "print(nf.layers[-1].data['labels'].asnumpy())\n",
    "print(g.nodes[nf.layer_parent_nid(-1)].data['labels'].asnumpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigger the computation in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dzzhen/Workspace/dgl/python/dgl/base.py:18: UserWarning: Initializer is not set. Use zero initializer instead. To suppress this warning, use `set_initializer` to explicitly specify which initializer to use.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "nf.layers[0].data['h'] = nf.layers[0].data['features']\n",
    "for i in range(nf.num_blocks):\n",
    "    nf.block_compute(i, fn.copy_src('h', 'msg'), fn.sum('msg', 'h'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train GCN with neighbor sampling\n",
    "In an $L$-layer graph convolution network (GCN), given a graph $G=(V, E)$, represented as an adjacency matrix $A$, with node features $H^{(0)} = X \\in \\mathbb{R}^{|V| \\times d}$, the hidden feature of a node $v$ in $(l+1)$-th layer $h_v^{(l+1)}$ depends on the features of all its neighbors in the previous layer $h_u^{(l)}$:\n",
    "$$\n",
    "z_v^{(l+1)} = \\sum_{u \\in \\mathcal{N}(v)} \\tilde{A}_{uv} h_u^{(l)} \\qquad h_v^{(l+1)} = \\sigma ( z_v^{(l+1)} W^{(l)})\n",
    "$$\n",
    "where $\\mathcal{N}(v)$ is the neighborhood of $v$, $\\tilde{A}$ could be any normalized version of $A$ such as $D^{-1} A$ in Kipf et al., $\\sigma(\\cdot)$ is an activation function, and $W^{(l)}$ is a trainable parameter of the $l$-th layer.\n",
    "\n",
    "The node update function is still the same as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeUpdate(gluon.Block):\n",
    "    def __init__(self, in_feats, out_feats, activation=None):\n",
    "        super(NodeUpdate, self).__init__()\n",
    "        self.dense = gluon.nn.Dense(out_feats, in_units=in_feats)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, node):\n",
    "        h = node.data['h']\n",
    "        h = self.dense(h)\n",
    "        if self.activation:\n",
    "            h = self.activation(h)\n",
    "        return {'activation': h}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using all the $L$-hop neighbors of a node $v$, [Hamilton et al.](https://arxiv.org/abs/1706.02216) propose *neighbor sampling*, which randomly samples a few neighbors $\\hat{\\mathcal{N}}^{(l)}(v)$ to estimate the aggregation $z_v^{(l+1)}$ of its total neighbors $\\mathcal{N}(v)$ in $l$-th GCN layer, by an unbiased estimator $\\hat{z}_v^{(l+1)}$\n",
    "$$\n",
    "\\hat{z}_v^{(l+1)} = \\frac{\\vert \\mathcal{N}(v) \\vert }{\\vert \\hat{\\mathcal{N}}^{(l)}(v) \\vert} \\sum_{u \\in \\hat{\\mathcal{N}}^{(l)}(v)} \\tilde{A}_{uv} \\hat{h}_u^{(l)} \\qquad\n",
    "\\hat{h}_v^{(l+1)} = \\sigma ( \\hat{z}_v^{(l+1)} W^{(l)} )\n",
    "$$\n",
    "Let $D^{(l)}$ be the number of neighbors to be sampled for each node at the $l$-th layer,\n",
    "then the receptive field size of each node can be controlled under $\\prod_{i=0}^{L-1} D^{(l)}$ by *neighbor sampling*.\n",
    "\n",
    "Here we define the node UDF which is a fully-connected layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNSampling(gluon.Block):\n",
    "    def __init__(self,\n",
    "                 in_feats,\n",
    "                 n_hidden,\n",
    "                 n_classes,\n",
    "                 n_layers,\n",
    "                 activation,\n",
    "                 dropout,\n",
    "                 **kwargs):\n",
    "        super(GCNSampling, self).__init__(**kwargs)\n",
    "        self.dropout = dropout\n",
    "        self.n_layers = n_layers\n",
    "        with self.name_scope():\n",
    "            self.layers = gluon.nn.Sequential()\n",
    "            # input layer\n",
    "            self.layers.add(NodeUpdate(in_feats, n_hidden, activation))\n",
    "            # hidden layers\n",
    "            for i in range(1, n_layers-1):\n",
    "                self.layers.add(NodeUpdate(n_hidden, n_hidden, activation))\n",
    "            # output layer\n",
    "            self.layers.add(NodeUpdate(n_hidden, n_classes))\n",
    "\n",
    "    def forward(self, nf):\n",
    "        nf.layers[0].data['activation'] = nf.layers[0].data['features']\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            h = nf.layers[i].data.pop('activation')\n",
    "            if self.dropout:\n",
    "                h = mx.nd.Dropout(h, p=self.dropout)\n",
    "            nf.layers[i].data['h'] = h\n",
    "            # block_compute() computes the feature of layer i given layer\n",
    "            # i-1, with the given message, reduce, and apply functions.\n",
    "            # Here, we essentially aggregate the neighbor node features in\n",
    "            # the previous layer, and update it with the `layer` function.\n",
    "            nf.block_compute(i,\n",
    "                             fn.copy_src(src='h', out='m'),\n",
    "                             lambda node : {'h': node.mailbox['m'].mean(axis=1)},\n",
    "                             layer)\n",
    "        h = nf.layers[-1].data.pop('activation')\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 844\n",
      "\n",
      "Epoch[0]: loss 1.9462796449661255\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 846\n",
      "\n",
      "Epoch[0]: loss 1.9235894680023193\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 848\n",
      "\n",
      "Epoch[1]: loss 1.8674328327178955\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 850\n",
      "\n",
      "Epoch[1]: loss 1.8281939029693604\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 852\n",
      "\n",
      "Epoch[2]: loss 1.7928876876831055\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 854\n",
      "\n",
      "Epoch[2]: loss 1.637632966041565\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 856\n",
      "\n",
      "Epoch[3]: loss 1.7567930221557617\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 858\n",
      "\n",
      "Epoch[3]: loss 1.579697608947754\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 860\n",
      "\n",
      "Epoch[4]: loss 1.6230899095535278\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 862\n",
      "\n",
      "Epoch[4]: loss 1.63848876953125\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 864\n",
      "\n",
      "Epoch[5]: loss 1.5719330310821533\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 866\n",
      "\n",
      "Epoch[5]: loss 1.4028629064559937\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 868\n",
      "\n",
      "Epoch[6]: loss 1.3958184719085693\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 870\n",
      "\n",
      "Epoch[6]: loss 1.489669919013977\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 872\n",
      "\n",
      "Epoch[7]: loss 1.3726001977920532\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 874\n",
      "\n",
      "Epoch[7]: loss 1.181177020072937\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 876\n",
      "\n",
      "Epoch[8]: loss 1.236330509185791\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 878\n",
      "\n",
      "Epoch[8]: loss 1.080051302909851\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 880\n",
      "\n",
      "Epoch[9]: loss 1.0920623540878296\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 882\n",
      "\n",
      "Epoch[9]: loss 1.167951226234436\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 884\n",
      "\n",
      "Epoch[10]: loss 1.0359869003295898\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 886\n",
      "\n",
      "Epoch[10]: loss 0.8606551289558411\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 888\n",
      "\n",
      "Epoch[11]: loss 0.8918370604515076\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 890\n",
      "\n",
      "Epoch[11]: loss 0.8770335912704468\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 892\n",
      "\n",
      "Epoch[12]: loss 0.7906259298324585\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 894\n",
      "\n",
      "Epoch[12]: loss 0.8567657470703125\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 896\n",
      "\n",
      "Epoch[13]: loss 0.7897965312004089\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 898\n",
      "\n",
      "Epoch[13]: loss 0.4833315312862396\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 900\n",
      "\n",
      "Epoch[14]: loss 0.6862680912017822\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 902\n",
      "\n",
      "Epoch[14]: loss 0.5166988372802734\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 904\n",
      "\n",
      "Epoch[15]: loss 0.5238171219825745\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 906\n",
      "\n",
      "Epoch[15]: loss 0.6338006258010864\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 908\n",
      "\n",
      "Epoch[16]: loss 0.523108959197998\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 910\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[16]: loss 0.34984031319618225\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 912\n",
      "\n",
      "Epoch[17]: loss 0.5049612522125244\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 914\n",
      "\n",
      "Epoch[17]: loss 0.23732736706733704\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 916\n",
      "\n",
      "Epoch[18]: loss 0.39064860343933105\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 918\n",
      "\n",
      "Epoch[18]: loss 0.30935874581336975\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 920\n",
      "\n",
      "Epoch[19]: loss 0.3868452310562134\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 922\n",
      "\n",
      "Epoch[19]: loss 0.2606932520866394\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 924\n",
      "\n",
      "Epoch[20]: loss 0.3930974304676056\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 926\n",
      "\n",
      "Epoch[20]: loss 0.16083136200904846\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 928\n",
      "\n",
      "Epoch[21]: loss 0.23932522535324097\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 930\n",
      "\n",
      "Epoch[21]: loss 0.27803167700767517\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 932\n",
      "\n",
      "Epoch[22]: loss 0.21923181414604187\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 934\n",
      "\n",
      "Epoch[22]: loss 0.25179439783096313\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 936\n",
      "\n",
      "Epoch[23]: loss 0.14121907949447632\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 938\n",
      "\n",
      "Epoch[23]: loss 0.3662179112434387\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 940\n",
      "\n",
      "Epoch[24]: loss 0.1809937059879303\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 942\n",
      "\n",
      "Epoch[24]: loss 0.2041269838809967\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 944\n",
      "\n",
      "Epoch[25]: loss 0.12162677943706512\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 946\n",
      "\n",
      "Epoch[25]: loss 0.16295787692070007\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 948\n",
      "\n",
      "Epoch[26]: loss 0.18762822449207306\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 950\n",
      "\n",
      "Epoch[26]: loss 0.09879570454359055\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 952\n",
      "\n",
      "Epoch[27]: loss 0.1557694971561432\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 954\n",
      "\n",
      "Epoch[27]: loss 0.06068132072687149\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 956\n",
      "\n",
      "Epoch[28]: loss 0.09551157057285309\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 958\n",
      "\n",
      "Epoch[28]: loss 0.2006213665008545\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 960\n",
      "\n",
      "Epoch[29]: loss 0.09105481207370758\n",
      "Error in autograd.Function.delete: Traceback (most recent call last):\n",
      "  File \"/Users/dzzhen/Workspace/incubator-mxnet/python/mxnet/autograd.py\", line 482, in delete_entry\n",
      "    del Function._registry.ref_holder[key]\n",
      "KeyError: 962\n",
      "\n",
      "Epoch[29]: loss 0.2335820198059082\n"
     ]
    }
   ],
   "source": [
    "# dropout probability\n",
    "dropout = 0.2\n",
    "# batch size\n",
    "batch_size = 100\n",
    "# number of neighbors to sample\n",
    "num_neighbors = 4\n",
    "# number of epochs\n",
    "num_epochs = 30\n",
    "\n",
    "# The number of classes we want to classify the nodes\n",
    "n_classes = data.num_labels\n",
    "# The number of layers of GCN.\n",
    "L = 2\n",
    "\n",
    "# initialize the model and cross entropy loss\n",
    "model = GCNSampling(in_feats, n_hidden, n_classes, L,\n",
    "                    mx.nd.relu, dropout, prefix='GCN')\n",
    "model.initialize()\n",
    "loss_fcn = gluon.loss.SoftmaxCELoss()\n",
    "\n",
    "# use adam optimizer\n",
    "trainer = gluon.Trainer(model.collect_params(), 'adam',\n",
    "                        {'learning_rate': 0.03, 'wd': 0})\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for nf in dgl.contrib.sampling.NeighborSampler(g, batch_size,\n",
    "                                                   num_neighbors,\n",
    "                                                   neighbor_type='in',\n",
    "                                                   shuffle=True,\n",
    "                                                   num_hops=L,\n",
    "                                                   seed_nodes=train_nid):\n",
    "        # When `NodeFlow` is generated from `NeighborSampler`, it only contains\n",
    "        # the topology structure, on which there is no data attached.\n",
    "        # Users need to call `copy_from_parent` to copy specific data,\n",
    "        # such as input node features, from the original graph.\n",
    "        nf.copy_from_parent()\n",
    "        with mx.autograd.record():\n",
    "            # forward\n",
    "            pred = model(nf)\n",
    "            batch_nids = nf.layer_parent_nid(-1).astype('int64')\n",
    "            batch_labels = labels[batch_nids]\n",
    "            # cross entropy loss\n",
    "            loss = loss_fcn(pred, batch_labels)\n",
    "            loss = loss.sum() / len(batch_nids)\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        # optimization\n",
    "        trainer.step(batch_size=1)\n",
    "        print(\"Epoch[{}]: loss {}\".format(epoch, loss.asscalar()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
